{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41681504249572754, 0.9192316125079704, 0.9410122562924206)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRIS\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sympy as sym\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial import distance\n",
    "import sympy as sym\n",
    "#data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "#Multilevel code\n",
    "import time \n",
    "t_begin = time.time()\n",
    "#compute local similarities \n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "k=4\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "M=np.zeros((X.shape[0],5,X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    M[i]=np.vstack((X[i],X[NN[i]]))\n",
    "W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]) :\n",
    "            W[i,j]=np.exp(-(A[i,j]**2)/1000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "#mean of each point and it's KNN\n",
    "def Z(f):\n",
    "    Z=np.zeros(X.shape[1])\n",
    "    for i in range(0,X.shape[1]):\n",
    "        Z[i]=np.dot(f.T[i],np.ones((k+1)))/(k+1)\n",
    "    return Z\n",
    "z=np.zeros((X.shape[0],X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    z[i]=Z(M[i])\n",
    "Z=np.matrix(z)\n",
    "##compute Global similarities (similarities of mean points)\n",
    "k1=16\n",
    "A1= pairwise_distances(Z, metric=\"euclidean\")\n",
    "DNN1, NN1 = np.sort(A), np.argsort(A1)\n",
    "NN1 = NN1[:,1:k1+1]\n",
    "DNN1 = DNN1[:,1:k1+1]\n",
    "W = np.zeros((Z.shape[0], Z.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN1[i])or(i in NN[j]) :\n",
    "            W[i][j] =np.exp(-(A[i,j]**2)/100)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "#Calculate the transformation matrix\n",
    "S=np.zeros((X.shape[0],X.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[0]):\n",
    "        if j in NN[i]:\n",
    "            S[i,j]=1\n",
    "            S[i,i]=1                          \n",
    "S=S/(k+1)\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "LL = D - W\n",
    "LL=np.dot(np.dot(S.T,LL),S)\n",
    "#local L+global \n",
    "L=LL+L\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "U = np.array(v.real[:,idx[0:3]])\n",
    "km = KMeans(init='k-means++', n_clusters=3)\n",
    "km.fit(U)\n",
    "#time,NMI,ARI\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5025920867919922, 0.4371895376620855, 0.3841121599603418)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WINE\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sympy as sym\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial import distance\n",
    "import sympy as sym \n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "X=data.data\n",
    "y=data.target\n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "k=9\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "M=np.zeros((X.shape[0],10,X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    M[i]=np.vstack((X[i],X[NN[i]]))\n",
    "W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]) :\n",
    "            W[i,j]=np.exp(-(A[i,j]**2)/10000000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "def Z(f):\n",
    "    Z=np.zeros(X.shape[1])\n",
    "    for i in range(0,X.shape[1]):\n",
    "        Z[i]=np.dot(f.T[i],np.ones(10))/10\n",
    "    return Z\n",
    "z=np.zeros((X.shape[0],X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    z[i]=Z(M[i])\n",
    "Z=np.matrix(z)\n",
    "k=10\n",
    "A1= pairwise_distances(Z, metric=\"euclidean\")\n",
    "DNN1, NN1 = np.sort(A), np.argsort(A1)\n",
    "NN1 = NN1[:,1:k+1]\n",
    "DNN1 = DNN1[:,1:k+1]\n",
    "W = np.zeros((Z.shape[0], Z.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN1[i])or(i in NN[j]) :\n",
    "            W[i][j] =np.exp(-(A[i,j]**2)/10)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "S=np.zeros((X.shape[0],X.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[0]):\n",
    "        if j in NN[i]:\n",
    "            S[i,j]=1\n",
    "            S[i,i]=1                          \n",
    "S=S/10\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "LL = D - W\n",
    "LL=np.dot(np.dot(S.T,LL),S)\n",
    "L=LL+L\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "U = np.array(v.real[:,idx[0:3]])\n",
    "km = KMeans(init='k-means++', n_clusters=3)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.216333150863647, 0.5747355915080968, 0.3833977493493344)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sympy as sym\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial import distance\n",
    "import sympy as sym \n",
    "from sklearn.datasets import fetch_openml\n",
    "dataset = fetch_openml(\"mnist_784\")\n",
    "X=dataset.data[:1000]\n",
    "y=dataset.target[:1000]\n",
    "X.shape\n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "k=9\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "M=np.zeros((X.shape[0],10,X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    M[i]=np.vstack((X[i],X[NN[i]]))\n",
    "W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]) :\n",
    "            W[i,j]=np.exp(-(A[i,j]**2)/10000000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "def Z(f):\n",
    "    Z=np.zeros(X.shape[1])\n",
    "    for i in range(0,X.shape[1]):\n",
    "        Z[i]=np.dot(f.T[i],np.ones(10))/10\n",
    "    return Z\n",
    "z=np.zeros((X.shape[0],X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    z[i]=Z(M[i])\n",
    "Z=np.matrix(z)\n",
    "k=5\n",
    "A1= pairwise_distances(Z, metric=\"euclidean\")\n",
    "DNN1, NN1 = np.sort(A), np.argsort(A1)\n",
    "NN1 = NN1[:,1:k+1]\n",
    "DNN1 = DNN1[:,1:k+1]\n",
    "W = np.zeros((Z.shape[0], Z.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN1[i])or(i in NN[j]) :\n",
    "            W[i][j] =np.exp(-(A[i,j]**2)/100)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "S=np.zeros((X.shape[0],X.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[0]):\n",
    "        if j in NN[i]:\n",
    "            S[i,j]=1\n",
    "            S[i,i]=1                          \n",
    "S=S/10\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "LL = D - W\n",
    "LL=np.dot(np.dot(S.T,LL),S)\n",
    "L=LL+L\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "U = np.array(v.real[:,idx[0:10]])\n",
    "km = KMeans(init='k-means++', n_clusters=10)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "#time,NMI,ARI\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.290183305740356, 0.8665211941644673, 0.6932834491623677)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COIL20\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sympy as sym\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial import distance\n",
    "import sympy as sym \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "import scipy.io as spio\n",
    "data = spio.loadmat(\"/Users/kazhal_e/Desktop/my info/data/COIL20.mat\")\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "y=np.zeros((1440))\n",
    "for k in range(1,21):\n",
    "    for i in range(1440):\n",
    "        if Y[i]==[k]:\n",
    "            y[i]=k     \n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "k=9\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "M=np.zeros((X.shape[0],10,X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    M[i]=np.vstack((X[i],X[NN[i]]))\n",
    "W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]) :\n",
    "            W[i,j]=np.exp(-(A[i,j]**2)/1000000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "def Z(f):\n",
    "    Z=np.zeros(X.shape[1])\n",
    "    for i in range(0,X.shape[1]):\n",
    "        Z[i]=np.dot(f.T[i],np.ones(10))/10\n",
    "    return Z\n",
    "z=np.zeros((X.shape[0],X.shape[1]))\n",
    "for i in range(0,X.shape[0]):\n",
    "    z[i]=Z(M[i])\n",
    "Z=np.matrix(z)\n",
    "k=10\n",
    "A1= pairwise_distances(Z, metric=\"euclidean\")\n",
    "DNN1, NN1 = np.sort(A), np.argsort(A1)\n",
    "NN1 = NN1[:,1:k+1]\n",
    "DNN1 = DNN1[:,1:k+1]\n",
    "W = np.zeros((Z.shape[0], Z.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN1[i])or(i in NN[j]) :\n",
    "            W[i][j] =np.exp(-(A[i,j]**2)/100)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "S=np.zeros((X.shape[0],X.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[0]):\n",
    "        if j in NN[i]:\n",
    "            S[i,j]=1\n",
    "            S[i,i]=1                          \n",
    "S=S/10\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "LL = D - W\n",
    "LL=np.dot(np.dot(S.T,LL),S)\n",
    "L=LL+L\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "U = np.array(v.real[:,idx[0:20]])\n",
    "km = KMeans(init='k-means++', n_clusters=20)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "#time,NMI,ARI\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
