{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1990342140197754, 0.8850620966553381, 0.9037675791580496)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IRIS\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sympy as sym\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from scipy.spatial import distance\n",
    "import sympy as sym\n",
    "from scipy.sparse import csr_matrix \n",
    "k=4\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "W=csr_matrix((X.shape[0], X.shape[0])).toarray()\n",
    "#W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]):\n",
    "            W[i,j] = np.exp(-(A[i,j]**2)/1000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "eps=np.max(e1)\n",
    "L=L/eps\n",
    "XTX=np.dot(X,X.T)\n",
    "e2,v2 = np.linalg.eig(XTX)\n",
    "idx2=np.argsort(e2)\n",
    "e2=e2[idx2]\n",
    "lam=np.max(e2)\n",
    "XTX=XTX/lam\n",
    "B=0.5\n",
    "GB=(1-B)*(np.identity(X.shape[0])-XTX)+(B*L)\n",
    "e3, v3 = np.linalg.eig(GB)\n",
    "idx3=np.argsort(e3)\n",
    "e3=e3[idx3]\n",
    "U = np.array(v3.real[:,idx3[0:3]])\n",
    "km = KMeans(init='k-means++', n_clusters=3)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.13945484161377, 0.5636334704283361, 0.4062810412199368)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plot \n",
    "from scipy.spatial import distance \n",
    "import math\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.cluster import SpectralClustering, KMeans \n",
    "from sklearn.metrics import pairwise_distances \n",
    "from matplotlib import pyplot as plt \n",
    "k =9\n",
    "from sklearn.datasets import fetch_openml\n",
    "dataset = fetch_openml(\"mnist_784\")\n",
    "X=dataset.data[:1000]\n",
    "y=dataset.target[:1000]\n",
    "X.shape\n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1] \n",
    "DNN = DNN[:,1:k+1]\n",
    "W=csr_matrix((X.shape[0], X.shape[0])).toarray()\n",
    "#W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if(j in NN[i])or(i in NN[j]):\n",
    "            W[i][j] =np.exp(-(A[i,j]**2)/10000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "eps=np.max(e1)\n",
    "L=L/eps\n",
    "XTX=np.dot(X,X.T)\n",
    "e2,v2 = np.linalg.eig(XTX)\n",
    "idx2=np.argsort(e2)\n",
    "e2=e2[idx2]\n",
    "lam=np.max(e2)\n",
    "XTX=XTX/lam\n",
    "B=0.5\n",
    "GB=(1-B)*(np.identity(X.shape[0])-XTX)+(B*L)\n",
    "e3, v3 = np.linalg.eig(GB)\n",
    "idx3=np.argsort(e3)\n",
    "e3=e3[idx3]\n",
    "U = np.array(v3.real[:,idx3[0:10]])\n",
    "km = KMeans(init='k-means++', n_clusters=10)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.555901050567627, 0.42836371356622555, 0.37140277111371683)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wine\n",
    "from sklearn import datasets\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plot\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "X=data.data\n",
    "y=data.target\n",
    "X.shape,np.min(y)\n",
    "import time \n",
    "t_begin = time.time()\n",
    "k=9\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "W=csr_matrix((X.shape[0], X.shape[0])).toarray()\n",
    "#W = np.zeros((X.shape[0], X.shape[0]))\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]):\n",
    "            W[i,j] = np.exp(-(A[i,j]**2)/1000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "eps=np.max(e1)\n",
    "L=L/eps\n",
    "XTX=np.dot(X,X.T)\n",
    "e2,v2 = np.linalg.eig(XTX)\n",
    "idx2=np.argsort(e2)\n",
    "e2=e2[idx2]\n",
    "lam=np.max(e2)\n",
    "XTX=XTX/lam\n",
    "B=0.7\n",
    "GB=(1-B)*(np.identity(X.shape[0])-XTX)+(B*L)\n",
    "e3, v3 = np.linalg.eig(GB)\n",
    "idx3=np.argsort(e3)\n",
    "e3=e3[idx3]\n",
    "U = np.array(v3.real[:,idx3[0:3]])\n",
    "km = KMeans(init='k-means++', n_clusters=3)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.082695722579956, 0.8808065048364832, 0.7808428900113675)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handwritten \n",
    "from sklearn import datasets\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.datasets import fetch_olivetti_faces \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plot\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "float_formatter = lambda x: \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "k=3\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X=digits.data\n",
    "y=digits.target\n",
    "import time \n",
    "t_begin = time.time()\n",
    "A= pairwise_distances(X, metric=\"euclidean\")\n",
    "DNN, NN = np.sort(A), np.argsort(A)\n",
    "NN = NN[:,1:k+1]\n",
    "DNN = DNN[:,1:k+1]\n",
    "W=csr_matrix((X.shape[0], X.shape[0])).toarray()\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[0]):\n",
    "        if (j in NN[i])or(i in NN[j]):\n",
    "            W[i,j] = np.exp(-(A[i,j]**2)/100000000)\n",
    "        else:\n",
    "            W[i][j]=0\n",
    "D = np.diag(np.sum(np.array(W), axis=1))\n",
    "L = D - W\n",
    "e1, v = np.linalg.eig(L)\n",
    "idx=np.argsort(e1)\n",
    "e1=e1[idx]\n",
    "eps=np.max(e1)\n",
    "L=L/eps\n",
    "XTX=np.dot(X,X.T)\n",
    "e2,v2 = np.linalg.eig(XTX)\n",
    "idx2=np.argsort(e2)\n",
    "e2=e2[idx2]\n",
    "lam=np.max(e2)\n",
    "XTX=XTX/lam\n",
    "B=0.9\n",
    "GB=(1-B)*(np.identity(X.shape[0])-XTX)+(B*L)\n",
    "e3, v3 = np.linalg.eig(GB)\n",
    "idx3=np.argsort(e3)\n",
    "e3=e3[idx3]\n",
    "U = np.array(v3.real[:,idx3[0:10]])\n",
    "km = KMeans(init='k-means++', n_clusters=10)\n",
    "km.fit(U)\n",
    "t_end = time.time()\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "t_end-t_begin,normalized_mutual_info_score(y,km.labels_,average_method='arithmetic'),adjusted_rand_score(y,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
